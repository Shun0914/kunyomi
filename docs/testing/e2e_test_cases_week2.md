# Week 2 E2Eテストケース

## 概要

Week 2で実装した機能に対するE2E（End-to-End）テストケースです。
実際のユーザー操作フローに沿ったテストシナリオを定義しています。

## テスト環境

- **フロントエンド**: http://localhost:3000
- **バックエンド**: http://localhost:8000
- **データベース**: ローカルMySQL（初期データ投入済み）

## テストデータの準備

### 前提条件

1. バックエンドサーバーが起動している
2. フロントエンドサーバーが起動している
3. データベースに初期データが投入されている
   - ジャンルマスターデータ
   - ユーザーデータ（テスト用）
   - ドキュメントデータ（テスト用、複数のキーワードが設定されている）

### 初期データ投入スクリプト

```bash
# バックエンドディレクトリで実行
cd backend

# ジャンルマスターデータ投入
python3 scripts/init_genres.py

# ユーザーデータ投入
python3 scripts/init_users.py

# ドキュメントデータ投入（キーワードが設定されている）
python3 scripts/init_documents.py
```

---

## テストケース

### TC-201: ドキュメント評価（役立った）

**目的**: ドキュメントに対して「役立った」評価が正しく記録されることを確認

**前提条件**:
- バックエンドサーバーが起動している
- ドキュメントデータが投入されている
- ユーザーデータが投入されている（評価用）

**手順**:
1. ブラウザで http://localhost:3000/document-list にアクセス
2. 任意のドキュメントをクリックして詳細画面を表示
3. 「役立った」ボタン（👍）をクリック
4. 評価結果を確認

**期待結果**:
- 「役立った」評価が記録される
- `helpful_count`が+1される
- `helpfulness_score`が更新される
- 評価ボタンの状態が更新される（評価済み表示）
- 評価後に同じドキュメントにアクセスしても、評価済みであることが表示される

---

### TC-202: ドキュメント評価（そうでもない）

**目的**: ドキュメントに対して「そうでもない」評価が正しく記録されることを確認

**前提条件**:
- バックエンドサーバーが起動している
- ドキュメントデータが投入されている
- ユーザーデータが投入されている（評価用）

**手順**:
1. ブラウザで http://localhost:3000/document-list にアクセス
2. 任意のドキュメントをクリックして詳細画面を表示
3. 「そうでもない」ボタン（👎）をクリック
4. 評価結果を確認

**期待結果**:
- 「そうでもない」評価が記録される
- 評価ボタンの状態が更新される（評価済み表示）
- 評価後に同じドキュメントにアクセスしても、評価済みであることが表示される

---

### TC-203: ドキュメント評価（重複評価の防止）

**目的**: 同一ユーザーが同じドキュメントに対して複数回評価できないことを確認

**前提条件**:
- バックエンドサーバーが起動している
- ドキュメントデータが投入されている
- ユーザーデータが投入されている（評価用）

**手順**:
1. ブラウザで http://localhost:3000/document-list にアクセス
2. 任意のドキュメントをクリックして詳細画面を表示
3. 「役立った」ボタン（👍）をクリック
4. ページをリロード
5. 再度「役立った」ボタン（👍）をクリックしようとする

**期待結果**:
- 既に評価済みであることが表示される
- 評価ボタンが無効化される、または「評価済み」表示になる
- バックエンドで重複評価が防がれる（エラーメッセージ、または既存評価の更新）

---

### TC-204: 役立ち度スコアの表示

**目的**: 役立ち度スコアが正しく表示されることを確認

**前提条件**:
- バックエンドサーバーが起動している
- ドキュメントデータが投入されている
- 複数のユーザーが評価している（テストデータ）

**手順**:
1. ブラウザで http://localhost:3000/document-list にアクセス
2. ドキュメント一覧で各ドキュメントの役立ち度スコアを確認
3. ドキュメント詳細画面で役立ち度スコアを確認

**期待結果**:
- 役立ち度スコアが数値（例: 4.5）で表示される
- スコアが高い順にソートされる（一覧画面の場合）
- スコアの計算が正しい（`helpful_count / MAX(view_count, 1)`）

---

### TC-205: 関連ドキュメント表示（キーワード類似度）

**目的**: キーワード類似度に基づいて関連ドキュメントが正しく表示されることを確認

**前提条件**:
- バックエンドサーバーが起動している
- 複数のドキュメントが投入されている（共通キーワードがある）
- キーワードが設定されている

**手順**:
1. ブラウザで http://localhost:3000/document-list にアクセス
2. 任意のドキュメントをクリックして詳細画面を表示
3. 「関連ドキュメント」セクションを確認

**期待結果**:
- 共通キーワードを持つドキュメントが表示される
- 関連度の高い順（共通キーワード数が多い順）にソートされる
- 関連ドキュメントをクリックすると、そのドキュメントの詳細画面に遷移する
- 関連ドキュメントがない場合は適切なメッセージが表示される

---

### TC-206: ナレッジネットワーク表示（グラフ可視化）

**目的**: ナレッジ間の関係がグラフで正しく可視化されることを確認

**前提条件**:
- バックエンドサーバーが起動している
- 複数のドキュメントが投入されている（キーワードが設定されている）
- フロントエンドでグラフ可視化コンポーネントが実装されている

**手順**:
1. ブラウザで http://localhost:3000/knowledge-network（またはグラフ画面URL）にアクセス
2. ナレッジネットワークグラフを確認
3. グラフ操作（ズームイン/アウト、パンなど）を試す
4. ノード（ドキュメント）をクリック

**期待結果**:
- ドキュメントがノードとして表示される
- 関連ドキュメント間がエッジ（線）で結ばれる
- ノードのサイズが役立ち度スコアや閲覧数に応じて変化する
- ノードの色が役立ち度スコアに応じて変化する
- ノードをクリックすると、そのドキュメントの詳細画面に遷移する
- ズームイン/アウト、パン操作が正常に動作する
- グラフの凡例が表示される

---

### TC-207: グラフ可視化のフィルタリング

**目的**: グラフ表示でフィルタリングが正しく動作することを確認

**前提条件**:
- バックエンドサーバーが起動している
- 複数のドキュメントが投入されている
- グラフ可視化コンポーネントが実装されている

**手順**:
1. ブラウザで http://localhost:3000/knowledge-network にアクセス
2. ジャンルフィルタで特定のジャンルを選択
3. グラフ表示を確認

**期待結果**:
- 選択したジャンルのドキュメントのみがグラフに表示される
- フィルタを解除すると、すべてのドキュメントが表示される
- フィルタリングが即座に反映される

---

### TC-208: エラーハンドリング（評価API）

**目的**: 評価APIのエラーハンドリングが適切に動作することを確認

**前提条件**:
- バックエンドサーバーが起動している
- ドキュメントデータが投入されている

**手順**:

#### TC-208-1: 存在しないドキュメントID

1. ブラウザで存在しないドキュメントIDの評価APIを直接呼び出す（開発者ツール）
2. エラーレスポンスを確認

**期待結果**:
- 404エラーが返される
- 適切なエラーメッセージが表示される

#### TC-208-2: ネットワークエラー

1. バックエンドサーバーを停止
2. ドキュメント詳細画面で「役立った」ボタンをクリック

**期待結果**:
- エラーメッセージが表示される
- 「評価の送信に失敗しました」などのユーザーフレンドリーなメッセージ

---

## テスト実行手順

### 1. 環境セットアップ

```bash
# バックエンドディレクトリで実行
cd backend
source venv/bin/activate
python3 -m uvicorn app.main:app --reload --host 0.0.0.0 --port 8000

# フロントエンドディレクトリで実行（別ターミナル）
cd frontend
npm run dev
```

### 2. テストデータの投入

```bash
# バックエンドディレクトリで実行
cd backend
source venv/bin/activate

# 初期データ投入
python3 scripts/init_genres.py
python3 scripts/init_users.py
python3 scripts/init_documents.py
```

### 3. テスト実行

各テストケース（TC-201〜TC-208）を順番に実行し、期待結果と比較します。

### 4. テスト結果の記録

- ✅ パス: 期待結果通りに動作した
- ❌ 失敗: 期待結果と異なる動作があった
- ⚠️ 保留: 実装未完了などでテストできない

---

## 注意事項

- E2Eテストは実際のブラウザで実行するため、時間がかかることがあります
- グラフ可視化のテストは、実装状況に応じて調整してください
- 評価機能のテストは、認証機能が実装されていない場合、仮のユーザーIDを使用します
- テストデータは毎回同じ状態にリセットすることを推奨します
- テスト実行前に、ブラウザのキャッシュをクリアすることを推奨します
- テストケースは実装状況に応じて更新してください

